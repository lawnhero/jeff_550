# ISOM 550 DDA Virtual TA Chains
# All chains are defined with LangChain Expression Language (LCEL) for streaming support
# Created for MBA Data and Decision Analytics course

from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser, PydanticOutputParser
from langchain_core.runnables import RunnableParallel, RunnablePassthrough
from operator import itemgetter
from typing import Dict, Any, Optional, Union, List
from langchain.schema.language_model import BaseLanguageModel
from pydantic import BaseModel, Field, validator

# Global output parser
output_parser = StrOutputParser()
class Label(BaseModel):
    """Pydantic model for router output."""
    query: str = Field(description="The new query generated by the router")
    label: str = Field(description="The classification label for the query")
    
    @validator('label')
    def validate_label(cls, v):
        """Validate that the label is one of the allowed values."""
        allowed_labels = [
             'course', 'contents'
        ]
        if v not in allowed_labels:
            raise ValueError(f'Label must be one of {allowed_labels}')
        return v

pydantic_parser = PydanticOutputParser(pydantic_object=Label)

def _format_docs(docs):
    """Format retrieved documents into a single string."""
    return "\n\n".join([doc.page_content for doc in docs])


def _create_simple_chain(template: str, llm: BaseLanguageModel, parser=output_parser) -> any:
    """Create a simple chain with template and LLM."""
    prompt = ChatPromptTemplate.from_template(template)
    return prompt | llm | parser


def _create_rag_chain(template: str, llm: BaseLanguageModel, retriever, parser=output_parser) -> any:
    """Create a RAG chain with retriever, template and LLM."""
    prompt = ChatPromptTemplate.from_template(template)
    setup = RunnableParallel({
        "context": retriever | _format_docs,
        "query": RunnablePassthrough()
    })
    return setup | prompt | llm | parser


# =============================================================================
# ROUTING CHAIN FOR COURSE KB SELECTION (NO BIND_TOOLS)
# =============================================================================

def create_routing_chain(llm: BaseLanguageModel):
    """Create a sophisticated routing chain that determines which course tool to use."""
    template = """You are an expert query classifier for an MBA Data Analytics Virtual TA system.
Your task is to analyze and classify the current query into the most appropriate category.

Current Query: <query>{query}</query>
Previous Conversation: {chat_history}

Classification Process:
1. Analyze the query and its context from previous conversation
2. Identify the primary topic and intent
3. Classify according to these categories:
   - course: Course logistics (syllabus, assignments, deadlines, grading, schedule, administrative info)
   - contents: Learning content (data analytics concepts, programming help, assignment guidance, explanations, examples)
4. Enchance the query to be more specific and relevant to the category without fundamental changes.

Guidelines:
- If asking about course structure, deadlines, policies → course
- If asking about concepts, coding, assignment help → contents
- Consider conversation context to maintain consistency
- When in doubt about learning vs logistics, prefer contents

Output a JSON object with:
1. "query": Enhanced version of the query for better processing
2. "label": Either "course" or "contents"

Response Format:
{{
    "query": "enhanced query text with relevant context",
    "label": "course or contents"
}}"""

    return _create_simple_chain(template, llm, parser=pydantic_parser)


def call_function(tool_name: str, query: str, chains_dict: dict, chat_history=None):
    """Invoke the appropriate chain based on the tool name."""
    
    # Get last two conversation turns for context
    if chat_history and len(chat_history) >= 2:
        recent_history = chat_history[-2:]
        history_text = "\n".join([f"{'Human' if i % 2 == 0 else 'AI'}: {msg.content}" for i, msg in enumerate(recent_history)])
    else:
        history_text = "No previous conversation"

    
    if "course" in tool_name:
        # Course logistics → RAG chain with course materials and chat history
        return chains_dict['rag_chain'].stream({
            "query": query,
            "chat_history": history_text
        })
    elif "contents" in tool_name:
        # Course contents/learning → Step chain with content materials and chat history
        return chains_dict['step_chain'].stream({
            "query": query,
            "chat_history": history_text
        })
  


# =============================================================================
# UNIFIED TA CHAIN WITH ROUTING (NO BIND_TOOLS)
# =============================================================================

def unified_ta_chain_with_tools(main_llm: BaseLanguageModel, router_llm: BaseLanguageModel, retriever_course, retriever_contents):
    """
    Unified Virtual TA chain that uses routing to determine which knowledge base to use.
    Uses a specialized router LLM for better routing decisions.
    """
    # Create individual chains using main LLM
    chain_dict = {
        'rag_chain': rag_chain(main_llm, retriever_course),
        'step_chain': step_chain(main_llm, retriever_contents),
        'class_chain': class_chain(main_llm)
    }
    
    # Create routing chain using specialized router LLM
    router = create_routing_chain(router_llm)
    
    return router, chain_dict


# =============================================================================
# ORIGINAL CHAINS (MAINTAINED FOR COMPATIBILITY)
# =============================================================================

def class_chain(llm: BaseLanguageModel):
    """
    Chain for in-class activities and analytical thinking.
    Handles explanations, practice problems, and software implementation queries.
    """
    template = """You are Dayton, a virtual TA for MBA Data and Decision Analytics. You facilitate in-class activities that encourage analytical thinking.

**Your Role:**
- Answer queries about data/decision analytics only
- Provide business-focused responses for MBA students
- Consider chat history when relevant

**Response Guidelines:**
Generate a response that is most appropriate for the query.
- For **Explanations**: Provide clear, concise answers
- For **Practice Problems**: Create 2 multiple-choice questions with code snippets, highlight correct answers with brief reasoning
- For **Software Help**: Give direct implementation guidance for Excel, JMP, Python, or SQL

**Format**: Keep responses under 300 words, use clear formatting, exclude XML tags.

**Query**: {query}

**Chat History**: {chat_history}

**Response**:"""

    prompt = ChatPromptTemplate.from_template(template)
    setup = RunnableParallel({
        "query": RunnablePassthrough(),
        "chat_history": itemgetter("chat_history")
    })
    return setup | prompt | llm | output_parser


def rag_chain(llm: BaseLanguageModel, retriever):
    """
    Chain for course logistics using RAG on course materials.
    Provides direct answers based on retrieved course content.
    Now includes conversation history for continuity.
    """
    template = """You are Dayton, virtual TA for MBA Data Analytics at Goizueta Business School. Answer the student's query on course logistics using ONLY the provided course materials.

**Instructions:**
1. Use only information from the retrieved context
2. Consider the previous conversation for continuity
3. Answer directly and concisely
4. Say "I don't have that information in the course materials" if not found

**Query**: {query}

**Course Materials**: {context}

**Previous Conversation**: {chat_history}

**Answer**:"""

    prompt = ChatPromptTemplate.from_template(template)
    setup = RunnableParallel({
        "context": itemgetter("query") | retriever | _format_docs,
        "query": itemgetter("query"),
        "chat_history": itemgetter("chat_history")
    })
    return setup | prompt | llm | output_parser


def step_chain(llm: BaseLanguageModel, retriever):
    """
    Chain for assignment help using Socratic method.
    Guides students step-by-step without giving final answers.
    Now includes conversation history for continuity.
    """
    template = """You are Dayton, a Socratic virtual TA for MBA Data Analytics. Guide students through their tasks using a step-by-step approach without giving final answers. Format your response in a clear and concise manner.

**Your Approach:**
1. Reference what's been covered in class (from context)
2. CAREFULLY review the previous conversation to see what has already been discussed
3. Identify where the student is in their learning journey based on the conversation
4. Provide ONLY the immediate next step that builds on what they've already established
5. DO NOT repeat information or steps already covered in the conversation

**Critical Instructions:**
- If the student has already provided context/variables, move to the next logical step in the process
- If they've already understood a concept, advance to application or interpretation
- Always progress the conversation forward, never backward
- Use "we" for more collaborative language

**If topic not covered**: Say "I don't believe this topic is covered in our class materials"

**Previous Conversation**: {chat_history}

**Class Materials**: {context}

**Query**: {query}


**Analysis and Next Step**:
Based on our previous discussion, you have already: [Acknowledge what's been established]


"""

    prompt = ChatPromptTemplate.from_template(template)
    setup = RunnableParallel({
        "context": itemgetter("query") | retriever | _format_docs,
        "query": itemgetter("query"),
        "chat_history": itemgetter("chat_history")
    })
    return setup | prompt | llm | output_parser


# =============================================================================
# HELPER FUNCTIONS
# =============================================================================

def get_all_chains(claude_sonnet, claude_haiku, retriever_course, retriever_contents, router_llm=None):
    """
    Convenience function to initialize all chains at once.
    
    Args:
        router_llm: Optional specialized LLM for routing decisions. If None, uses claude_sonnet.
    
    Returns:
        dict: Dictionary containing all initialized chains
    """
    # Use provided router LLM or default to claude_sonnet
    if router_llm is None:
        router_llm = claude_sonnet
    
    # Create router and chain dict for routing
    router, chain_dict = unified_ta_chain_with_tools(
        main_llm=claude_sonnet, 
        router_llm=router_llm,
        retriever_course=retriever_course, 
        retriever_contents=retriever_contents
    )
    
    return {
        'class_chain': class_chain(claude_sonnet),
        'rag_chain': rag_chain(claude_haiku, retriever_course),
        'step_chain': step_chain(claude_sonnet, retriever_contents),
        'router': router,
        'chain_dict': chain_dict
    }
